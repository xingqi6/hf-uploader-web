# app.py (V43.0 æš´åŠ›æ¸…æ‰« & è¡¥æ¼ç‰ˆ)
import os
import sys
import time
import json
import threading
import smtplib
import logging
import queue
import shutil
from email.mime.text import MIMEText
from email.header import Header
from email.utils import formataddr
from flask import Flask, render_template, request, jsonify, Response
from huggingface_hub import HfApi

# å¼ºåˆ¶ UTF-8
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

app = Flask(__name__)

# ================= å…¨å±€é…ç½® =================
CONFIG_FILE = "/app/config/settings.json"
DATA_DIR = "/app/data"
LOG_QUEUE = queue.Queue(maxsize=500)
FAILURE_RECORD_FILE = "/app/config/failures.json"

DEFAULT_CONFIG = {
    "hf_endpoint": "https://hf-mirror.com", 
    "hf_token": "", "repo_id": "", "repo_type": "dataset", "remote_folder": "",
    "email_host": "", "email_port": "", "email_user": "", "email_pass": "", "email_to": "",
    "warn_timeout": 900, "kill_timeout": 1800, "idle_interval": 1800,
    "max_retries": 5, "notify_min_size": 1024, "file_interval": 15, 
    "delete_after_upload": True,
    "enable_hf_transfer": False,
    "enable_idle_email": False,
    "stability_duration": 30 # é»˜è®¤æ”¹ä¸º30ç§’ï¼ŒåŠ å¿«å“åº”
}

uploader_thread = None
stop_event = threading.Event()
is_running = False

# æ—¥å¿—é…ç½®
class QueueHandler(logging.Handler):
    def emit(self, record):
        try:
            msg = self.format(record)
            if LOG_QUEUE.full():
                try: LOG_QUEUE.get_nowait()
                except: pass
            LOG_QUEUE.put(msg)
        except: pass

logger = logging.getLogger("HF_Uploader")
logger.setLevel(logging.INFO)
web_formatter = logging.Formatter('%(message)s') 
q_handler = QueueHandler()
q_handler.setFormatter(web_formatter)
logger.addHandler(q_handler)

console_formatter = logging.Formatter('%(asctime)s - %(message)s', datefmt='%H:%M:%S')
console_handler = logging.StreamHandler()
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)

JUNK_FILES = {'.DS_Store', 'Thumbs.db', 'desktop.ini', '@eaDir', '.smbdelete'}

def load_config():
    if not os.path.exists(CONFIG_FILE): return DEFAULT_CONFIG.copy()
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            config = DEFAULT_CONFIG.copy()
            if "stability_duration" not in config: config["stability_duration"] = 30
            if "enable_hf_transfer" not in config: config["enable_hf_transfer"] = False
            if "enable_idle_email" not in config: config["enable_idle_email"] = False
            config.update(data)
            return config
    except: return DEFAULT_CONFIG.copy()

def save_config(config):
    try:
        os.makedirs(os.path.dirname(CONFIG_FILE), exist_ok=True)
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except: return False

def load_failures():
    if not os.path.exists(FAILURE_RECORD_FILE): return {}
    try:
        with open(FAILURE_RECORD_FILE, 'r', encoding='utf-8') as f: return json.load(f)
    except: return {}

def save_failures(data):
    try:
        with open(FAILURE_RECORD_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except: pass

def safe_int(value, default):
    try:
        if value is None or str(value).strip() == "": return default
        return int(value)
    except: return default

def send_email(cfg, title, content):
    if not cfg.get('email_user') or not cfg.get('email_pass'): return
    try:
        formatted = content.replace('\n', '<br>')
        time_str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        msg = MIMEText(f"<h3>{title}</h3><p>{formatted}</p><hr><p style='font-size:12px;color:gray'>{time_str} | NASåŠ©æ‰‹</p>", 'html', 'utf-8')
        msg['From'] = formataddr(("NASåŠ©æ‰‹", cfg['email_user']))
        msg['To'] = formataddr(("æˆ‘", cfg['email_to']))
        msg['Subject'] = Header(title, 'utf-8')
        
        host = cfg.get('email_host') if cfg.get('email_host') else "smtp.qq.com"
        port = safe_int(cfg.get('email_port'), 465)
        
        smtp = smtplib.SMTP_SSL(host, port, timeout=30)
        smtp.login(cfg['email_user'], cfg['email_pass'])
        smtp.sendmail(cfg['email_user'], [cfg['email_to']], msg.as_string())
        smtp.quit()
        logger.info(f"ğŸ“§ [é‚®ä»¶] å‘é€æˆåŠŸ: {title}")
    except Exception as e:
        logger.error(f"âš ï¸ [é‚®ä»¶] å‘é€å¤±è´¥: {str(e)}")

def recursive_delete_empty(path):
    try:
        if path == DATA_DIR or not path.startswith(DATA_DIR): return
        if os.path.isdir(path):
            files = os.listdir(path)
            valid = [f for f in files if f not in JUNK_FILES and not f.startswith('.')]
            if not valid:
                for f in files:
                    try:
                        p = os.path.join(path, f)
                        if os.path.isdir(p): shutil.rmtree(p)
                        else: os.remove(p)
                    except: pass
                os.rmdir(path)
                logger.info(f"ğŸ§¹ [æ¸…ç†] ç©ºæ–‡ä»¶å¤¹å·²åˆ é™¤: {os.path.basename(path)}")
                recursive_delete_empty(os.path.dirname(path))
    except: pass

def check_remote_success(api, repo_id, repo_type, remote_path, local_size):
    try:
        info = api.get_paths_info(
            repo_id=repo_id,
            repo_type=repo_type,
            paths=[remote_path],
        )
        if len(info) > 0:
            if info[0].size == local_size: return True
    except:
        return False
    return False

# ğŸŒŸ V40 æ ¸å¿ƒï¼šæ–‡ä»¶å¤¹ç¨³å®šæ€§æ ¡éªŒ
def check_folder_stability(folder_path, duration):
    logger.info(f"ğŸ›¡ï¸ [æ ¡éªŒ] æ­£åœ¨æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§ï¼Œè¯·ç­‰å¾… {duration}ç§’...")
    snapshot1 = {}
    try:
        for root, _, files in os.walk(folder_path):
            for f in files:
                p = os.path.join(root, f)
                snapshot1[p] = {'size': os.path.getsize(p), 'mtime': os.path.getmtime(p)}
        
        time.sleep(duration)
        
        snapshot2 = {}
        for root, _, files in os.walk(folder_path):
            for f in files:
                p = os.path.join(root, f)
                snapshot2[p] = {'size': os.path.getsize(p), 'mtime': os.path.getmtime(p)}
        
        if len(snapshot1) != len(snapshot2): return False
        for p, meta in snapshot1.items():
            if p not in snapshot2: return False
            if meta['size'] != snapshot2[p]['size'] or meta['mtime'] != snapshot2[p]['mtime']:
                logger.info(f"â³ [å†™å…¥ä¸­] æ–‡ä»¶å˜åŒ–: {os.path.basename(p)}")
                return False
        return True
    except: return False

def uploader_daemon(config):
    global is_running
    endpoint = config.get('hf_endpoint', 'https://hf-mirror.com')
    use_accel = config.get('enable_hf_transfer', False)
    mode_str = "ğŸš€ é«˜é€Ÿæ¨¡å¼" if use_accel else "ğŸ¢ ç¨³å®šæ¨¡å¼"
    
    logger.info(f"ğŸš€ æœåŠ¡å¯åŠ¨ | ç›®æ ‡: {endpoint} | {mode_str}")
    
    os.environ["HF_ENDPOINT"] = endpoint
    if use_accel:
        os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "1"
    else:
        if "HF_HUB_ENABLE_HF_TRANSFER" in os.environ: del os.environ["HF_HUB_ENABLE_HF_TRANSFER"]
    
    try:
        api = HfApi(token=config['hf_token'], endpoint=endpoint)
        user = api.whoami()
        logger.info(f"âœ… ç™»å½•æˆåŠŸ: {user['name']}")
    except Exception as e:
        logger.error(f"âŒ ç™»å½•å¤±è´¥: {str(e)}")
        is_running = False
        return

    history_file = os.path.join(os.path.dirname(CONFIG_FILE), "history.json")
    uploaded_files = set()
    if os.path.exists(history_file):
        try:
            with open(history_file, 'r') as f: uploaded_files = set(json.load(f))
        except: pass

    last_busy = time.time()
    last_idle = 0
    is_idle_mode = False

    while not stop_event.is_set():
        try:
            # ğŸŒŸ 0. å®æ—¶æ‰«æåé¦ˆ
            logger.debug(f"ğŸ” æ­£åœ¨æ‰«ææ–°æ–‡ä»¶...")
            
            all_files = []
            
            # 1. æ‰«æä¸æ®‹ç•™è¡¥æ¼
            for root, dirs, files in os.walk(DATA_DIR):
                has_temp_file = False
                for f in files: # æ£€æŸ¥è¿…é›·ä¸´æ—¶æ–‡ä»¶
                    if f.endswith(('.xltd', '.tmp', '.download')): has_temp_file = True; break
                if has_temp_file: continue
                
                for file in files:
                    if file.startswith('.') or file.endswith('.json'): continue
                    if file in JUNK_FILES: continue
                    
                    full = os.path.join(root, file)
                    rel = os.path.relpath(full, DATA_DIR).replace("\\", "/")
                    
                    # ğŸŒŸ V43 æ ¸å¿ƒæ”¹è¿›ï¼šå³ä½¿åœ¨å†å²è®°å½•é‡Œï¼Œå¦‚æœæœ¬åœ°æ–‡ä»¶è¿˜åœ¨ï¼Œä¹Ÿå¾—å¤„ç†ï¼
                    if rel in uploaded_files:
                        # æ£€æŸ¥æ˜¯å¦çœŸçš„ä¸Šä¼ äº†
                        remote_f = config.get('remote_folder', '')
                        if not remote_f or remote_f.strip() == "": remote_f = "."
                        remote_p = f"{remote_f}/{rel}" if remote_f != "." else rel
                        
                        # åªæœ‰å½“å¼€å¯äº†è‡ªåŠ¨åˆ é™¤ï¼Œä¸”æ–‡ä»¶æ»ç•™åœ¨æœ¬åœ°æ—¶ï¼Œæ‰è¿›è¡Œâ€œè¡¥åˆ€â€æ£€æŸ¥
                        if config.get('delete_after_upload', True):
                            logger.info(f"ğŸ§ [è¡¥æ¼] å‘ç°æ®‹ç•™æ–‡ä»¶: {file}ï¼Œæ­£åœ¨æ ¸å®äº‘ç«¯...")
                            if check_remote_success(api, config['repo_id'], config['repo_type'], remote_p, os.path.getsize(full)):
                                logger.info(f"ğŸ—‘ï¸ [è¡¥åˆ€] äº‘ç«¯å·²å­˜åœ¨ï¼Œæ‰§è¡Œåˆ é™¤: {file}")
                                try:
                                    os.remove(full)
                                    recursive_delete_empty(os.path.dirname(full))
                                except: pass
                                continue # åˆ å®Œäº†å°±è·³è¿‡ä¸Šä¼ 
                            else:
                                logger.info(f"âš ï¸ [é‡ä¼ ] äº‘ç«¯ç¼ºå¤±ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—: {file}")
                                # ä»å†å²è®°å½•ç§»é™¤ï¼Œä»¥ä¾¿é‡æ–°ä¸Šä¼ 
                                uploaded_files.discard(rel)
                    
                    # åŠ å…¥å¾…ä¼ åˆ—è¡¨
                    all_files.append((full, rel))

            if all_files:
                is_idle_mode = False
                tasks_by_folder = {}
                for full, rel in all_files:
                    folder = os.path.dirname(rel)
                    if not folder: folder = "æ ¹ç›®å½•"
                    if folder not in tasks_by_folder: tasks_by_folder[folder] = []
                    tasks_by_folder[folder].append((full, rel))

                logger.info(f"ğŸ“¦ å‘ç° {len(all_files)} ä¸ªå¾…å¤„ç†æ–‡ä»¶")
                failures_db = load_failures()

                for folder_name, tasks in tasks_by_folder.items():
                    if stop_event.is_set(): break
                    
                    # æ–‡ä»¶å¤¹åŸå­é”æ ¡éªŒ
                    folder_abs_path = os.path.dirname(tasks[0][0])
                    stability_time = safe_int(config.get('stability_duration'), 30) # V43 é»˜è®¤30ç§’
                    
                    if not check_folder_stability(folder_abs_path, stability_time):
                        logger.info(f"â³ [ç­‰å¾…] æ–‡ä»¶å¤¹ '{folder_name}' æ­£åœ¨å†™å…¥ï¼Œè·³è¿‡...")
                        continue 

                    logger.info(f"ğŸ”’ [é”å®š] æ–‡ä»¶å¤¹ '{folder_name}' æ ¡éªŒé€šè¿‡ï¼Œå¼€å§‹ä¸Šä¼ ...")
                    folder_success_count = 0
                    tasks.sort(key=lambda x: x[1])

                    for i, (local_p, rel_p) in enumerate(tasks):
                        if stop_event.is_set(): break
                        
                        file_name = os.path.basename(rel_p)
                        if i > 0: time.sleep(safe_int(config.get('file_interval'), 15))

                        remote_f = config.get('remote_folder', '')
                        if not remote_f or remote_f.strip() == "": remote_f = "."
                        remote_p = f"{remote_f}/{rel_p}" if remote_f != "." else rel_p
                        size_mb = os.path.getsize(local_p) / (1024*1024)

                        logger.info(f"â–¶ [å¼€å§‹] ä¸Šä¼ : {file_name} ({size_mb:.1f} MB)")

                        success = False
                        max_retries = safe_int(config.get('max_retries'), 5)
                        
                        for attempt in range(max_retries):
                            if stop_event.is_set(): break
                            try:
                                api.upload_file(
                                    path_or_fileobj=local_p, 
                                    path_in_repo=remote_p,
                                    repo_id=config['repo_id'],
                                    repo_type=config['repo_type'],
                                    token=config['hf_token']
                                )
                                success = True
                                break
                            except Exception as e:
                                err_str = str(e)
                                logger.info(f"âš ï¸ æ ¡éªŒè¿œç¨‹çŠ¶æ€...")
                                if check_remote_success(api, config['repo_id'], config['repo_type'], remote_p, os.path.getsize(local_p)):
                                    logger.info(f"ğŸ‰ [æ¡æ¼] è¿œç¨‹æ–‡ä»¶å·²å­˜åœ¨ï¼Œè§†ä¸ºæˆåŠŸï¼")
                                    success = True
                                    break
                                
                                backoff = 30 * (2 ** attempt)
                                logger.warning(f"âŒ [é‡è¯•] ç¬¬{attempt+1}æ¬¡å¤±è´¥ï¼Œä¼‘æ¯ {backoff}ç§’...")
                                time.sleep(backoff)
                                if "401" in err_str: 
                                    try: api = HfApi(token=config['hf_token'], endpoint=endpoint)
                                    except: pass

                        if success:
                            logger.info(f"âœ… [æˆåŠŸ] ä»»åŠ¡å®Œæˆ: {file_name}")
                            uploaded_files.add(rel_p)
                            with open(history_file, 'w') as f: json.dump(list(uploaded_files), f)
                            
                            if rel_p in failures_db:
                                del failures_db[rel_p]
                                save_failures(failures_db)

                            folder_success_count += 1
                            
                            if size_mb >= safe_int(config.get('notify_min_size'), 1024):
                                send_email(config, "å¤§æ–‡ä»¶ä¸Šä¼ æˆåŠŸ", f"æ–‡ä»¶: {rel_p}")

                            if config.get('delete_after_upload', True):
                                try:
                                    os.remove(local_p)
                                    logger.info(f"ğŸ—‘ï¸ [åˆ é™¤] æœ¬åœ°æ–‡ä»¶: {file_name}")
                                    recursive_delete_empty(os.path.dirname(local_p))
                                except: pass
                        else:
                            logger.error(f"â›” [å¤±è´¥] æ”¾å¼ƒä¸Šä¼ : {file_name}")
                            current_time = time.time()
                            if rel_p not in failures_db:
                                failures_db[rel_p] = current_time
                                save_failures(failures_db)
                            else:
                                if (current_time - failures_db[rel_p]) > 86400:
                                    send_email(config, "ä¸¥é‡ï¼šæ–‡ä»¶å¤±è´¥è¶…24å°æ—¶", f"æ–‡ä»¶: {rel_p}")
                                    failures_db[rel_p] = current_time
                                    save_failures(failures_db)

                    if folder_success_count > 0:
                        status_text = "æœ¬åœ°å·²æ¸…ç†" if config.get('delete_after_upload', True) else "ä¿ç•™"
                        msg = f"ç›®å½•ï¼š{folder_name}<br>æˆåŠŸï¼š{folder_success_count} ä¸ª<br>çŠ¶æ€ï¼š{status_text}"
                        send_email(config, "NASæ–‡ä»¶å¤¹ä»»åŠ¡å®Œæˆ", msg)
                        logger.info(f"ğŸ‰ [å®Œæˆ] ç›®å½• {folder_name} å¤„ç†å®Œæ¯•")

                last_busy = time.time()
            else:
                if not is_idle_mode:
                    logger.info("ğŸ’¤ ä»»åŠ¡å·²å®Œæˆï¼Œè¯·ç»§ç»­æ·»åŠ æ–‡ä»¶...")
                    is_idle_mode = True
                
                now = time.time()
                if config.get('enable_idle_email', False):
                    if (now - last_busy) > safe_int(config.get('idle_interval'), 1800):
                        if (now - last_idle) > safe_int(config.get('idle_interval'), 1800):
                            send_email(config, "ç©ºé—²æé†’", "NASç©ºé—²ä¸­")
                            last_idle = now
            
            for _ in range(5):
                if stop_event.is_set(): break
                time.sleep(1)
                
        except Exception as e:
            logger.error(f"âš ï¸ ç³»ç»Ÿé”™è¯¯: {e}")
            time.sleep(10)
    is_running = False
    logger.info("ğŸ›‘ è¿›ç¨‹å·²åœæ­¢")

@app.route('/')
def index():
    return render_template('index.html', config=load_config(), is_running=is_running)

@app.route('/help')
def help_page():
    return render_template('help.html')

@app.route('/save', methods=['POST'])
def save_settings():
    if is_running: return jsonify({"status": "error", "msg": "ğŸš« è¯·å…ˆã€åœæ­¢æœåŠ¡ã€‘å†ä¿å­˜ï¼"})
    try:
        cfg = request.json
        if not cfg.get('hf_token'): return jsonify({"status": "error", "msg": "âŒ Token ä¸ºç©º"})
        if not cfg.get('repo_id'): return jsonify({"status": "error", "msg": "âŒ ä»“åº“ID ä¸ºç©º"})

        cfg['email_port'] = safe_int(cfg.get('email_port'), 465)
        cfg['warn_timeout'] = safe_int(cfg.get('warn_timeout'), 900)
        cfg['kill_timeout'] = safe_int(cfg.get('kill_timeout'), 1800)
        cfg['idle_interval'] = safe_int(cfg.get('idle_interval'), 1800)
        cfg['max_retries'] = safe_int(cfg.get('max_retries'), 3)
        cfg['notify_min_size'] = safe_int(cfg.get('notify_min_size'), 1024)
        cfg['file_interval'] = safe_int(cfg.get('file_interval'), 15)
        cfg['stability_duration'] = safe_int(cfg.get('stability_duration'), 30)
        
        cfg['hf_token'] = str(cfg['hf_token']).strip()

        if save_config(cfg): return jsonify({"status": "success", "msg": "âœ… ä¿å­˜æˆåŠŸ"})
        else: return jsonify({"status": "error", "msg": "âŒ å†™å…¥å¤±è´¥"})
    except Exception as e: return jsonify({"status": "error", "msg": f"âŒ é”™è¯¯: {str(e)}"})

@app.route('/reset', methods=['POST'])
def reset_settings():
    if is_running: return jsonify({"status": "error", "msg": "ğŸš« è¿è¡Œä¸­æ— æ³•é‡ç½®"})
    try:
        if os.path.exists(CONFIG_FILE): os.remove(CONFIG_FILE)
        if os.path.exists(FAILURE_RECORD_FILE): os.remove(FAILURE_RECORD_FILE)
        return jsonify({"status": "success", "msg": "ğŸ—‘ï¸ é…ç½®å·²æ¸…ç©º"})
    except Exception as e: return jsonify({"status": "error", "msg": f"âŒ é”™è¯¯: {str(e)}"})

@app.route('/start', methods=['POST'])
def start_worker():
    global uploader_thread, is_running, stop_event
    if is_running: return jsonify({"status": "warning", "msg": "âš ï¸ å·²åœ¨è¿è¡Œ"})
    cfg = load_config()
    stop_event.clear()
    uploader_thread = threading.Thread(target=uploader_daemon, args=(cfg,))
    uploader_thread.daemon = True
    uploader_thread.start()
    is_running = True
    return jsonify({"status": "success", "msg": "ğŸš€ å¯åŠ¨æˆåŠŸ"})

@app.route('/stop', methods=['POST'])
def stop_worker():
    global stop_event
    stop_event.set()
    return jsonify({"status": "success", "msg": "ğŸ›‘ æ­£åœ¨åœæ­¢..."})

@app.route('/logs')
def stream_logs():
    def generate():
        while True:
            if not LOG_QUEUE.empty():
                yield f"data: {LOG_QUEUE.get()}\n\n"
            else:
                time.sleep(0.5)
                yield f"data: \n\n"
    return Response(generate(), mimetype='text/event-stream')

if __name__ == '__main__':
    os.makedirs("/app/config", exist_ok=True)
    os.makedirs("/app/data", exist_ok=True)
    app.run(host='0.0.0.0', port=7860, debug=False, use_reloader=False, threaded=True)
